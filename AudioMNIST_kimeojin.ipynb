{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AudioMNIST \n",
    "## RNN\n",
    "### 20213013 김어진"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. 데이터 분석"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Audio MNIST 데이터셋 특징\n",
    "- 목표: 음성 신호를 통해 0부터 9까지의 숫자를 인식하는 모델을 훈련.\n",
    "- 형태: 각 숫자(0~9) 음성 파일은 WAV 형식으로 저장되어 있습니다. 각 음성 파일은 숫자를 발음한 오디오 클립.\n",
    "- 샘플: 각 오디오 파일은 고유한 숫자 음성을 포함하고 있으며, 일반적으로 각 숫자에 대해 여러 샘플이 존재.\n",
    "\n",
    "#### 구성 요소\n",
    "- 샘플링 레이트: 일반적으로 음성 데이터는 일정한 샘플링 레이트. Audio MNIST의 경우, 보통 16kHz(16,000 샘플/초) 샘플링 레이트로 저장.\n",
    "- 길이: 각 오디오 클립의 길이는 일정하지 않으며, 대체로 몇 백 밀리초 정도.\n",
    "- 레이블: 각 음성 파일은 해당 숫자를 레이블(0~9)화한 음성.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### waveform / mel-spectrogram\n",
    "- waveform: 오디오 신호의 시간 영역 표현. 시간에 따른 음압의 변화를 시각화.\n",
    "- mel-spectrogram: 주파수 영역 표현. 음성 신호를 주파수 대역으로 분해하고, 각 주파수 대역의 에너지 크기를 시각화.\n",
    "\n",
    "6가지 모델 구성\n",
    "- Waveform + RNN\n",
    "- Waveform + LSTM\n",
    "- Waveform + GRU\n",
    "- Mel-Spectrogram + RNN\n",
    "- Mel-Spectrogram + LSTM\n",
    "- Mel-Spectrogram + GRU"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 데이터 로드"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with 'Python 3.10.0' requires the ipykernel package.\n",
      "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: 'c:/Users/chosun/AppData/Local/Programs/Python/Python310/python.exe -m pip install ipykernel -U --user --force-reinstall'"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# audio_mnist.pt 파일 로드\n",
    "file_path = 'audio_mnist.pt'  # 파일 경로 설정\n",
    "audio_data = torch.load(file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# waveform 시각화\n",
    "# 데이터 구조 확인\n",
    "print(type(audio_data))  # 데이터 타입 확인\n",
    "print(audio_data.keys())  # 데이터 내 key 확인\n",
    "\n",
    "# Waveform 데이터 추출 및 시각화\n",
    "waveform_sample = audio_data['waveform'][0]  # 첫 번째 샘플 사용 (키는 예시)\n",
    "sample_rate = audio_data['sample_rate']  # 샘플 레이트 (있다면)\n",
    "\n",
    "# Waveform 시각화\n",
    "plt.figure(figsize=(12, 4))\n",
    "plt.plot(waveform_sample.numpy())\n",
    "plt.title(\"Audio MNIST Waveform Sample\")\n",
    "plt.xlabel(\"Time\")\n",
    "plt.ylabel(\"Amplitude\")\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
